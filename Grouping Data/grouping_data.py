# -*- coding: utf-8 -*-
"""Grouping_data.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14zHFIvu47kMtHJelmYgWJLwyEi0Jk4hm

# Grouping Data
*This modulewe will learn how we can find out many different answers to quesions using just one dataset span across multiple parameters.
## Contents
  * Downloading data
  * How to group on different parameters for multiple results.
  * Getting the Comtrade Data
  * Pattern of Split-Apply-Combine
  * Filtering the data
"""

import pandas as pd
import warnings
warnings.simplefilter('ignore')

"""## Downloading Data
* We are going to download using pandas <pre>download()</pre> 
* The GDP of UK, China from the year 2008 to 2013.
"""

from pandas_datareader import wb
YEAR = 2013 #Constant variables.
GDP_INDICATOR = 'NY.GDP.MKTP.CD'
data = wb.download(indicator = GDP_INDICATOR, country=['GB','CN'], start=YEAR-5, end=YEAR) 
data = data.reset_index() #reseting index will reset the indexex into columns.
data

"""## Grouping Data
* Grouping allows us to analyze data onto many frontiers.
* We will use pandas's <pre>Groupby(<i>column_name</i>)</pre> for grouping data columns.
* To apply aggregate functions on the data we will use <pre>pandas.Dataframe.<b>aggregate()</b></pre>
"""

#Find the total sum of GDP for each country over all the years.
data.groupby('country')['NY.GDP.MKTP.CD'].aggregate(sum)

#Total combined GDP of two countries in each year.
data.groupby('year')[GDP_INDICATOR].aggregate(sum)

"""## Getting the Comtrade data
* Comtrade database is UN's import export data base of the world.
* You will learn to fetch data from the URL itself usning Comtrade API.
"""

URL='http://comtrade.un.org/api/get?max=5000&type=C&freq=A&px=HS&ps=2014%2C2013%2C2012&r=826&p=all&rg=all&cc=0401%2C0402&fmt=csv'

df=pd.read_csv(URL, dtype={'Commodity Code':str, 'Reporter Code':str}) #here Commodity code is given in str becaue it will return 401 for 0401 otherwise.

#To save a copy of this data file to your folder we use to_csv() function.
df.to_csv('Data_copy.csv', index=False) # Index=false is to aviod pandas to assign its default index in the new file. 
#check the Files(Folder symbol) tab on the left hand side and you will find the copied file.

df.head()

"""## Pattern of Split-apply-combine
* To perform operations on hetereogenous dataset and to figure an answer to a particular question  then this pattern is used.
* We create a smaller dataset for understanding.
"""

#Creating a smaller data
data=[['A',10],['A',15],['A',5],['A',20],

              ['B',10],['B',10],['B',5],

              ['C',20],['C',30]] 

df=pd.DataFrame(data=data, columns=["Commodity","Amount"])
df

#Splitting the data or grouping.
grouped_data = df.groupby('Commodity')
grouped_data

#performing operations
grouped_data.groups.keys()

grouped_data.get_group('A') #returns only A commodity data.

#Applying the sumary or aggregation on the group.
grouped_data.aggregate(sum) #this calculates the sum of each groupand combines the result in a flat table.

def top2ByAmount(g):
  return g.sort_values('Amount', ascending=False).head(2) #Display only top 2 amounts.
grouped_data.apply(top2ByAmount)

"""## Filtering the data 
* Sometimes for analysis there is only a need of the subset of the data fromteh dataset.
* There may be requirement of only that groups that satisfy some constraints.
* For filtering pandas has <pre>filter()</pre>
* The filter() method uses a function that returns a boolean ( True or False ) value to decide whether or not to filter through the rows associated with a particular group.
"""

#Getting the groups with atmost 3 rows.
def groupsOfAtMost3Rows(g):
  return len(g) <= 3

grouped_data.aggregate(len)

grouped_data.filter(groupsOfAtMost3Rows)